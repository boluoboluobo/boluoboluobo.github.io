<!DOCTYPE html>
<html lang="zh-CN">
    <head>
  <!-- 元数据 -->
  <meta charset="utf-8">
  <link rel="icon" href="">
  <title>深度学习入门笔记06 | 菠萝菠萝卜的博客</title>
  <meta name="author" content="菠萝菠萝卜" />
  <meta http-equiv="Cache-Control" content="no-transform" />
  <meta http-equiv="Cache-Control" content="no-siteapp" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="robots" content="index,follow" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  <meta name="format-detection" content="telphone=no, email=no" />
  
    <meta name="keywords" content="DeepLearning, numpy, python" />
  
  <meta name="description" content="参数更新这里就是将之前的权重更新的算法，封装成一个类。每个类里面都有一个update方法，这样往后如果需要修改更新权重的方法（SGD，Momentum，AdaGrad，Adm），直接更改对应类的对象即可。 e.g 12345678network &#x3D; TwoLayersNet(...)optimizer &#x3D; SGD() #此处可以更换更新方法...for i in range(50000):">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习入门笔记06">
<meta property="og:url" content="https://www.boluoboluobo.top/2021/09/30/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B006/index.html">
<meta property="og:site_name" content="菠萝菠萝卜的博客">
<meta property="og:description" content="参数更新这里就是将之前的权重更新的算法，封装成一个类。每个类里面都有一个update方法，这样往后如果需要修改更新权重的方法（SGD，Momentum，AdaGrad，Adm），直接更改对应类的对象即可。 e.g 12345678network &#x3D; TwoLayersNet(...)optimizer &#x3D; SGD() #此处可以更换更新方法...for i in range(50000):">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://www.boluoboluobo.top/2021/09/30/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B006/sdxx.webp">
<meta property="article:published_time" content="2021-09-30T02:08:23.000Z">
<meta property="article:modified_time" content="2021-11-05T04:58:25.881Z">
<meta property="article:author" content="菠萝菠萝卜">
<meta property="article:tag" content="python">
<meta property="article:tag" content="DeepLearning">
<meta property="article:tag" content="numpy">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://www.boluoboluobo.top/2021/09/30/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B006/sdxx.webp">
<meta name="twitter:site" content="@null">
  
  <!-- 站点验证相关 -->
  
    
    
    
  
  <!-- 样式表文件 -->
  <link rel="stylesheet" id="kratos-css" href="/css/kratosr.min.css" type="text/css" media="all">
  
    <link rel="stylesheet" id="highlight-css" href="/css/highlight/night-eighties.min.css" type="text/css" media="all">
  
  
  <link rel="stylesheet" id="fontawe-css" href="https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css" type="text/css" media="all">
  <link rel="stylesheet" id="nprogress-css" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css" type="text/css" media="all">
  
  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer@1.10.1/dist/APlayer.min.css">
  
  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css">
  
  
    <link rel="stylesheet" id="darkmode-css" href="/css/kr-dark.min.css" type="text/css" media="all">
  
  <!-- 不得不预先加载的一些JS文件 -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js"></script>
  
    <script src="https://cdn.jsdelivr.net/npm/qrcode_js@1.0.0/qrcode.min.js"></script>
  
<meta name="generator" content="Hexo 5.4.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head>


    <body class="custom-background">
        <div id="kratos-wrapper">
    <div id="kratos-page">
        <div id="kratos-header">
            <header id="kratos-desktop-topnav" class="kratos-topnav">
                <div class="container">
                    <div class="nav-header">
                        <nav id="kratos-menu-wrap">
                            <ul id="kratos-primary-menu" class="sf-menu">
                                
                                    
                                        <li><a href="/"><i class="fa fa-home"></i>首页</a></li>
                                    
                                
                                    
                                        <li><a href="/archives/"><i class="fa fa-file"></i>档案馆</a></li>
                                    
                                
                                    
                                        <li>
                                            <a><i class="fa fa-link"></i>链接</a>
                                            <ul class="sub-menu">
                                                
                                                    
                                                
                                                    
                                                        <li><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_36571422">CSDN博客</a></li>
                                                    
                                                
                                            </ul>
                                        </li>
                                    
                                
                            </ul>
                        </nav>
                    </div>
                </div>
            </header>
            <header id="kratos-mobile-topnav" class="kratos-topnav">
                <div class="container">
                    <div class="color-logo"><a href="/">菠萝菠萝卜的博客</a></div>
                    <div class="nav-toggle">
                        <a class="kratos-nav-toggle js-kratos-nav-toggle">
                            <i></i>
                        </a>
                    </div>
                </div>
            </header>
        </div>
        <div class="kratos-start kratos-hero-2">
            <!-- <div class="kratos-overlay"></div> -->
            <div class="kratos-cover kratos-cover-2 text-center">
                <div class="desc desc2 animate-box">
                    <a href="/">
                        <h2>菠萝菠萝卜的博客</h2> <br />
                        <span></span>
                    </a>
                </div>
            </div>
        </div>

        <div id="kratos-blog-post">
            <div class="container">
                <div id="main" class="row">
                    

        <section class="col-md-8">
    <article>
        <div class="kratos-hentry kratos-post-inner clearfix">
            <header class="kratos-entry-header">
                <h1 class="kratos-entry-title text-center">深度学习入门笔记06</h1>
                
                <ul class="kratos-post-meta text-center">
                    <li><i class="fa fa-calendar"></i> 2021-09-30</li>
                    <li><i class="fa fa-user"></i> 作者 菠萝菠萝卜</li>
                    <li>
                        <i class="fa fa-edit"></i> 
                        
                        
                            ~6.84K
                        
                        字
                    </li>
                    
                        <li id="/2021/09/30/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B006/" class="leancloud_visitors" data-flag-title="深度学习入门笔记06">
                            <i class="fa fa-eye"></i>
                            <span class="leancloud-visitors-count"> </span> 次阅读
                        </li>
                        
                    
                </ul>
            </header>
            <div class="kratos-post-content">
                <div id="expire-alert" class="alert alert-warning hidden" role="alert">
                    本文最后编辑于 <time datetime="1636088305881"></time> 前，其中的内容可能需要更新。
                </div>
                
                    <div class="kratos-post-inner-toc">
                        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8F%82%E6%95%B0%E6%9B%B4%E6%96%B0"><span class="toc-number">1.</span> <span class="toc-text">参数更新</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#SGD"><span class="toc-number">1.1.</span> <span class="toc-text">SGD</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#SGD%E7%BC%BA%E7%82%B9"><span class="toc-number">1.1.1.</span> <span class="toc-text">SGD缺点</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Momentum"><span class="toc-number">1.2.</span> <span class="toc-text">Momentum</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#AdaGrad"><span class="toc-number">1.3.</span> <span class="toc-text">AdaGrad</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Adm"><span class="toc-number">1.4.</span> <span class="toc-text">Adm</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%9D%83%E9%87%8D%E7%9A%84%E5%88%9D%E5%A7%8B%E5%80%BC"><span class="toc-number">2.</span> <span class="toc-text">权重的初始值</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9A%90%E8%97%8F%E5%B1%82%E7%9A%84%E6%BF%80%E6%B4%BB%E5%80%BC%E7%9A%84%E5%88%86%E5%B8%83"><span class="toc-number">2.1.</span> <span class="toc-text">隐藏层的激活值的分布</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ReLu%E5%88%9D%E5%A7%8B%E5%80%BC"><span class="toc-number">2.2.</span> <span class="toc-text">ReLu初始值</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Batch-Normalization"><span class="toc-number">3.</span> <span class="toc-text">Batch Normalization</span></a></li></ol>
                    </div>
                
                <hr />
                <h1 id="参数更新"><a href="#参数更新" class="headerlink" title="参数更新"></a>参数更新</h1><p>这里就是将之前的权重更新的算法，封装成一个类。每个类里面都有一个update方法，这样往后如果需要修改更新权重的方法（SGD，Momentum，AdaGrad，Adm），直接更改对应类的对象即可。</p>
<p>e.g</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">network = TwoLayersNet(...)</span><br><span class="line">optimizer = SGD() <span class="comment">#此处可以更换更新方法</span></span><br><span class="line">...</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">50000</span>):</span><br><span class="line">    ...</span><br><span class="line">    grads = network.gradient(x_batch,y_batch)</span><br><span class="line">    params = network.params</span><br><span class="line">    optimizer.update(params,grads)</span><br></pre></td></tr></table></figure>
<h2 id="SGD"><a href="#SGD" class="headerlink" title="SGD"></a>SGD</h2><p>随机梯度下降法，和之前一样，这里只是做了封装</p>
<p>python实现</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment">#随机梯度下降法</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SGD</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,lr = <span class="number">0.01</span></span>):</span></span><br><span class="line">        self.lr = lr</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update</span>(<span class="params">self,params,grads</span>):</span></span><br><span class="line">        <span class="keyword">for</span> key <span class="keyword">in</span> params.keys():</span><br><span class="line">            params[key] -= self.lr * grads[key]</span><br></pre></td></tr></table></figure>
<h3 id="SGD缺点"><a href="#SGD缺点" class="headerlink" title="SGD缺点"></a>SGD缺点</h3><p>SGD的下降方式呈现“之”字形，比较低效。</p>
<h2 id="Momentum"><a href="#Momentum" class="headerlink" title="Momentum"></a>Momentum</h2><p>数学表达：</p>
<script type="math/tex; mode=display">
v \larr \alpha v - \eta \frac {\sigma L}{\sigma W} \\\\
W = W + v</script><p>此处的v相当于物理中的速度，α模拟的阻力。这种方法会更快的向x轴靠近，减少之字形带来的影响。</p>
<h2 id="AdaGrad"><a href="#AdaGrad" class="headerlink" title="AdaGrad"></a>AdaGrad</h2><p><strong>学习率衰减法：</strong>随着学习进行，学习率逐渐变小，开始多学，后面少学。</p>
<p>数学公式：</p>
<script type="math/tex; mode=display">
h \larr h + \frac {\sigma L}{\sigma W} ⊙ \frac {\sigma L}{\sigma W} \\\\
W \larr W - \eta \frac {1}{\sqrt {h}} \frac {\sigma L}{\sigma W}</script><p>新变量h，它保存了以前所有梯度值的平方和，更新参数时，通过乘以1除根号h，调整学习尺度。参数的元素中变动较大的元素的学习率将变小。</p>
<p>python实现</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#学习率衰减</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AdaGrad</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,lr = <span class="number">0.01</span></span>):</span></span><br><span class="line">        self.lr = lr</span><br><span class="line">        self.h = <span class="literal">None</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update</span>(<span class="params">self,params,grads</span>):</span></span><br><span class="line">        <span class="keyword">if</span> self.h <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            self.h = {}</span><br><span class="line">            <span class="keyword">for</span> key,val <span class="keyword">in</span> params.items():</span><br><span class="line">                self.h[key] = np.zeros_like(val)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> key <span class="keyword">in</span> params.keys():</span><br><span class="line">            self.h[key] += grads[key] * grads[key]</span><br><span class="line">            params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + <span class="number">1e-7</span>)</span><br></pre></td></tr></table></figure>
<h2 id="Adm"><a href="#Adm" class="headerlink" title="Adm"></a>Adm</h2><p>这里具体原理没有详讲，只是贴下代码</p>
<p>python实现</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Adam</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, lr=<span class="number">0.001</span>, beta1=<span class="number">0.9</span>, beta2=<span class="number">0.999</span></span>):</span></span><br><span class="line">        self.lr = lr</span><br><span class="line">        self.beta1 = beta1</span><br><span class="line">        self.beta2 = beta2</span><br><span class="line">        self.<span class="built_in">iter</span> = <span class="number">0</span></span><br><span class="line">        self.m = <span class="literal">None</span></span><br><span class="line">        self.v = <span class="literal">None</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update</span>(<span class="params">self, params, grads</span>):</span></span><br><span class="line">        <span class="keyword">if</span> self.m <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            self.m, self.v = {}, {}</span><br><span class="line">            <span class="keyword">for</span> key, val <span class="keyword">in</span> params.items():</span><br><span class="line">                self.m[key] = np.zeros_like(val)</span><br><span class="line">                self.v[key] = np.zeros_like(val)</span><br><span class="line">        </span><br><span class="line">        self.<span class="built_in">iter</span> += <span class="number">1</span></span><br><span class="line">        lr_t  = self.lr * np.sqrt(<span class="number">1.0</span> - self.beta2**self.<span class="built_in">iter</span>) / (<span class="number">1.0</span> - self.beta1**self.<span class="built_in">iter</span>)         </span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> key <span class="keyword">in</span> params.keys():</span><br><span class="line">            <span class="comment">#self.m[key] = self.beta1*self.m[key] + (1-self.beta1)*grads[key]</span></span><br><span class="line">            <span class="comment">#self.v[key] = self.beta2*self.v[key] + (1-self.beta2)*(grads[key]**2)</span></span><br><span class="line">            self.m[key] += (<span class="number">1</span> - self.beta1) * (grads[key] - self.m[key])</span><br><span class="line">            self.v[key] += (<span class="number">1</span> - self.beta2) * (grads[key]**<span class="number">2</span> - self.v[key])</span><br><span class="line">            </span><br><span class="line">            params[key] -= lr_t * self.m[key] / (np.sqrt(self.v[key]) + <span class="number">1e-7</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment">#unbias_m += (1 - self.beta1) * (grads[key] - self.m[key]) # correct bias</span></span><br><span class="line">            <span class="comment">#unbisa_b += (1 - self.beta2) * (grads[key]*grads[key] - self.v[key]) # correct bias</span></span><br><span class="line">            <span class="comment">#params[key] += self.lr * unbias_m / (np.sqrt(unbisa_b) + 1e-7)</span></span><br></pre></td></tr></table></figure>
<h1 id="权重的初始值"><a href="#权重的初始值" class="headerlink" title="权重的初始值"></a>权重的初始值</h1><p>权重的初始值设定很重要，这个会导致学习是否会快速进行</p>
<h2 id="隐藏层的激活值的分布"><a href="#隐藏层的激活值的分布" class="headerlink" title="隐藏层的激活值的分布"></a>隐藏层的激活值的分布</h2><p>假设这里有5层神经网络，激活函数使用sigmoid，传入随机数据，观察分布。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> / (<span class="number">1</span> + np.exp(-x))</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ReLu</span>(<span class="params">x</span>):</span></span><br><span class="line">    m = (x &lt;= <span class="number">0</span>)</span><br><span class="line">    x[m] = <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">x = np.random.randn(<span class="number">1000</span>,<span class="number">100</span>) <span class="comment">#1000个数据</span></span><br><span class="line">node_num = <span class="number">100</span>      <span class="comment">#各个隐藏层的节点数量</span></span><br><span class="line">hidden_layer_size = <span class="number">5</span> <span class="comment">#5个隐藏层</span></span><br><span class="line">activations = {}    <span class="comment">#激活值的结果保存在这里</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(hidden_layer_size):</span><br><span class="line">    <span class="keyword">if</span> i != <span class="number">0</span>:</span><br><span class="line">        x = activations[i - <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    w = np.random.randn(node_num, node_num) * <span class="number">1</span></span><br><span class="line">    z = np.dot(x,w)</span><br><span class="line">    a = ReLu(z)</span><br><span class="line">    activations[i] = a</span><br><span class="line"><span class="comment">#绘图</span></span><br><span class="line"><span class="keyword">for</span> i, a <span class="keyword">in</span> activations.items():</span><br><span class="line">    plt.subplot(<span class="number">1</span>,<span class="built_in">len</span>(activations),i+<span class="number">1</span>)</span><br><span class="line">    plt.title(<span class="built_in">str</span>(i) + <span class="string">"-layer"</span>)</span><br><span class="line">    plt.hist(a.flatten(), <span class="number">30</span> , <span class="built_in">range</span>=(<span class="number">0</span>,<span class="number">1</span>))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>out:</p>
<p><img src="/2021/09/30/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B006/hist1.jpg" alt></p>
<p>这个代码中主要关注的是权重的尺度，标准差的选择。从图中看，由于是sigmoid函数，随着输出不断靠近0或1，他的导数值逐渐接近0，因此偏向0和1的数据分布会造成反向传播中梯度的值不断变小，最后消失。这个问题就是<strong>梯度消失</strong>。层次加深的深度学习中，梯度消失问题会更加严重。</p>
<p>将标准差变为0.01后</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">w = np.random.randn(node_num, node_num) * <span class="number">0.01</span></span><br></pre></td></tr></table></figure>
<p>out:</p>
<p><img src="/2021/09/30/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B006/hist2.jpg" alt></p>
<p>这次呈现集中在0.5分布，不会发生梯度消失问题。激活值的分布有所偏向，在表现力上会有问题，多个神经元输出几乎相同的值，那他们也没有存在的意义了。</p>
<p>尝试Xavier Glorot推荐的权重初始值:</p>
<p>如果前一层的节点数为n，则初始值使用标准差为1/√n 的分布</p>
<p><img src="/2021/09/30/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B006/hist3.jpg" alt></p>
<p>从结果可知，越是后面的层，图像变得更歪斜，呈现了比之前更有的广度分布。因为各层间传递的数据有适当的广度，sigmoid表现力不受限制。</p>
<h2 id="ReLu初始值"><a href="#ReLu初始值" class="headerlink" title="ReLu初始值"></a>ReLu初始值</h2><p>推荐Kaiming He初始值，也称为“He初始值”，使用标准差为√(2/n)的高斯分布。</p>
<h1 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h1><p>使用Batch Normalization，使得各层拥有适当的广度，“强制性”的调整各层的激活值分布。</p>
<p>优点：</p>
<ul>
<li><p>使得学习更加快速进行</p>
</li>
<li><p>不那么依赖初始值</p>
</li>
<li><p>抑制过拟合</p>
</li>
</ul>
<p>为了有适当的广度，所以需要在神经网络中添加正规化层，就是Batch Normalization层。</p>
<p>BN层做的事情就是使得数据分布为0、方差为1的正规化。过程如下</p>
<p><img src="/2021/09/30/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B006/math.jpg" alt></p>
<p>这里ε是一个极小值，防止下边变为0导致计算错误。</p>
<p>此处γ的值初始值为1，β值为0，后续通过学习调整到合适的值。</p>
<p>python实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BatchNormalization</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    http://arxiv.org/abs/1502.03167</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, gamma, beta, momentum=<span class="number">0.9</span>, running_mean=<span class="literal">None</span>, running_var=<span class="literal">None</span></span>):</span></span><br><span class="line">        self.gamma = gamma</span><br><span class="line">        self.beta = beta</span><br><span class="line">        self.momentum = momentum</span><br><span class="line">        self.input_shape = <span class="literal">None</span> <span class="comment"># Conv层的情况下为4维，全连接层的情况下为2维  </span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 测试时使用的平均值和方差</span></span><br><span class="line">        self.running_mean = running_mean</span><br><span class="line">        self.running_var = running_var  </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># backward时使用的中间数据</span></span><br><span class="line">        self.batch_size = <span class="literal">None</span></span><br><span class="line">        self.xc = <span class="literal">None</span></span><br><span class="line">        self.std = <span class="literal">None</span></span><br><span class="line">        self.dgamma = <span class="literal">None</span></span><br><span class="line">        self.dbeta = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, train_flg=<span class="literal">True</span></span>):</span></span><br><span class="line">        self.input_shape = x.shape</span><br><span class="line">        <span class="keyword">if</span> x.ndim != <span class="number">2</span>:</span><br><span class="line">            N, C, H, W = x.shape</span><br><span class="line">            x = x.reshape(N, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        out = self.__forward(x, train_flg)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> out.reshape(*self.input_shape)</span><br><span class="line">            </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__forward</span>(<span class="params">self, x, train_flg</span>):</span></span><br><span class="line">        <span class="keyword">if</span> self.running_mean <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            N, D = x.shape</span><br><span class="line">            self.running_mean = np.zeros(D)</span><br><span class="line">            self.running_var = np.zeros(D)</span><br><span class="line">                        </span><br><span class="line">        <span class="keyword">if</span> train_flg:</span><br><span class="line">            mu = x.mean(axis=<span class="number">0</span>)</span><br><span class="line">            xc = x - mu</span><br><span class="line">            var = np.mean(xc**<span class="number">2</span>, axis=<span class="number">0</span>)</span><br><span class="line">            std = np.sqrt(var + <span class="number">10e-7</span>)</span><br><span class="line">            xn = xc / std</span><br><span class="line">            </span><br><span class="line">            self.batch_size = x.shape[<span class="number">0</span>]</span><br><span class="line">            self.xc = xc</span><br><span class="line">            self.xn = xn</span><br><span class="line">            self.std = std</span><br><span class="line">            self.running_mean = self.momentum * self.running_mean + (<span class="number">1</span>-self.momentum) * mu</span><br><span class="line">            self.running_var = self.momentum * self.running_var + (<span class="number">1</span>-self.momentum) * var            </span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            xc = x - self.running_mean</span><br><span class="line">            xn = xc / ((np.sqrt(self.running_var + <span class="number">10e-7</span>)))</span><br><span class="line">            </span><br><span class="line">        out = self.gamma * xn + self.beta </span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span>(<span class="params">self, dout</span>):</span></span><br><span class="line">        <span class="keyword">if</span> dout.ndim != <span class="number">2</span>:</span><br><span class="line">            N, C, H, W = dout.shape</span><br><span class="line">            dout = dout.reshape(N, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        dx = self.__backward(dout)</span><br><span class="line"></span><br><span class="line">        dx = dx.reshape(*self.input_shape)</span><br><span class="line">        <span class="keyword">return</span> dx</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__backward</span>(<span class="params">self, dout</span>):</span></span><br><span class="line">        dbeta = dout.<span class="built_in">sum</span>(axis=<span class="number">0</span>)</span><br><span class="line">        dgamma = np.<span class="built_in">sum</span>(self.xn * dout, axis=<span class="number">0</span>)</span><br><span class="line">        dxn = self.gamma * dout</span><br><span class="line">        dxc = dxn / self.std</span><br><span class="line">        dstd = -np.<span class="built_in">sum</span>((dxn * self.xc) / (self.std * self.std), axis=<span class="number">0</span>)</span><br><span class="line">        dvar = <span class="number">0.5</span> * dstd / self.std</span><br><span class="line">        dxc += (<span class="number">2.0</span> / self.batch_size) * self.xc * dvar</span><br><span class="line">        dmu = np.<span class="built_in">sum</span>(dxc, axis=<span class="number">0</span>)</span><br><span class="line">        dx = dxc - dmu / self.batch_size</span><br><span class="line">        </span><br><span class="line">        self.dgamma = dgamma</span><br><span class="line">        self.dbeta = dbeta</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> dx</span><br></pre></td></tr></table></figure>

            </div>
            
                <div class="kratos-copyright text-center clearfix">
                    <h5>本作品采用 <a rel="license nofollow" target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/">知识共享署名-相同方式共享 4.0 国际许可协议</a> 进行许可</h5>
                </div>
            
            <footer class="kratos-entry-footer clearfix">
                
                    <div class="post-like-donate text-center clearfix" id="post-like-donate">
                    
                        <a class="donate" href="javascript:;"><i class="fa fa-bitcoin"></i> 打赏</a>
                    
                    
                        <a class="share" href="javascript:;"><i class="fa fa-share-alt"></i> 分享</a>
                        <div class="share-wrap" style="display: none;">
    <div class="share-group">
        <a href="javascript:;" class="share-plain qq" onclick="share('qq');" rel="nofollow">
            <div class="icon-wrap">
                <i class="fa fa-qq"></i>
            </div>
        </a>
        <a href="javascript:;" class="share-plain qzone" onclick="share('qzone');" rel="nofollow">
            <div class="icon-wrap">
                <i class="fa fa-star"></i>
            </div>
        </a>
        <a href="javascript:;" class="share-plain weixin pop style-plain" rel="nofollow">
            <div class="icon-wrap">
                <i class="fa fa-weixin"></i>
            </div>
            <div class="share-int">
                <div class="qrcode" id="wechat-qr"></div>
                <p>打开微信“扫一扫”，打开网页后点击屏幕右上角分享按钮</p>
            </div>
        </a>
        <a href="javascript:;" class="share-plain weibo" onclick="share('weibo');" rel="nofollow">
            <div class="icon-wrap">
                <i class="fa fa-weibo"></i>
            </div>
        </a>
        <a href="javascript:;" class="share-plain facebook style-plain" onclick="share('facebook');" rel="nofollow">
            <div class="icon-wrap">
                <i class="fa fa-facebook"></i>
            </div>
        </a>
        <a href="javascript:;" class="share-plain twitter style-plain" onclick="share('twitter');" rel="nofollow">
            <div class="icon-wrap">
                <i class="fa fa-twitter"></i>
            </div>
        </a>
    </div>
    <script type="text/javascript">
        $(()=>{
            new QRCode("wechat-qr", {
                text: "https://www.boluoboluobo.top/2021/09/30/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B006/",
                width: 150,
                height: 150,
                correctLevel : QRCode.CorrectLevel.H
            });
        });
        function share(dest) {
            const qqBase        = "https://connect.qq.com/widget/shareqq/index.html?";
            const weiboBase     = "https://service.weibo.com/share/share.php?";
            const qzoneBase     = "https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?";
            const facebookBase  = "https://www.facebook.com/sharer/sharer.php?";
            const twitterBase   = "https://twitter.com/intent/tweet?";
            const hostUrl       = "https://www.boluoboluobo.top/2021/09/30/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B006/";
            const title         = "「深度学习入门笔记06」";
            const excerpt       = `参数更新这里就是将之前的权重更新的算法，封装成一个类。每个类里面都有一个update方法，这样往后如果需要修改更新权重的方法（SGD，Momentum，AdaGrad，Adm），直接更改对应类的对象即可。
e.g
12345678ne...`;
            let _URL;
            switch (dest) {
                case "qq"       : _URL = qqBase+"url="+hostUrl+"&title="+title+"&desc=&summary="+excerpt+"&site=cxpy";     break;
                case "weibo"    : _URL = weiboBase+"url="+hostUrl+"&title="+title+excerpt;                                 break;
                case "qzone"    : _URL = qzoneBase+"url="+hostUrl+"&title="+title+"&desc=&summary="+excerpt+"&site=cxpy";  break;
                case "facebook" : _URL = facebookBase+"u="+hostUrl;                                                        break;
                case "twitter"  : _URL = twitterBase+"text="+title+excerpt+"&url="+hostUrl;                                break;
            }
            window.open(_URL);
        };
    </script>
</div>
                    
                    </div>
                
                <div class="footer-tag clearfix">
                    <div class="pull-left">
                    <i class="fa fa-tags"></i>
                        <a class="tag-none-link" href="/tags/DeepLearning/" rel="tag">DeepLearning</a>, <a class="tag-none-link" href="/tags/numpy/" rel="tag">numpy</a>, <a class="tag-none-link" href="/tags/python/" rel="tag">python</a>
                    </div>
                    <div class="pull-date">
                    <span>最后编辑：2021-11-05</span>
                    </div>
                </div>
            </footer>
        </div>
        
            <nav class="navigation post-navigation clearfix" role="navigation">
                
                <div class="nav-previous clearfix">
                    <a title=" pytorch笔记02" href="/2021/09/29/pytorch入门笔记02/">&lt; 上一篇</a>
                </div>
                
                
                <div class="nav-next clearfix">
                    <a title=" 深度学习入门笔记07" href="/2021/10/07/深度学习入门笔记07/">下一篇 &gt;</a>
                </div>
                
            </nav>
        
        
            <div id="v-comments" class="post-comments"></div>
<script>
    var load_comm = () => {
        const init = () => {
            new Valine({
                el: '#v-comments',
                appId: 'pnDNVddr900afG7XglGQgJCb-gzGzoHsz',
                appKey: 'HA3J9tdvziBrLcSml8Kai0qH',
                visitor: true,
                enableQQ: false,
                path: '/2021/09/30/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B006/',
				avatar: ''
            });
        }
        if (typeof Valine == 'undefined') {
            const src = 'https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js';
            $.getScript(src, init);
        } else {
            init();
        }
    };
</script>
<noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="https://valine.js.org/">comments powered by Valine.</a></noscript>

        
    </article>
</section>

                
            

<section id="kratos-widget-area" class="col-md-4 hidden-xs hidden-sm">
    <!-- 文章和页面根据splitter来分割，没有的话就从头开始设置为sticky -->
    
    
                <aside id="krw-about" class="widget widget-kratos-about clearfix">
    <div class="photo-background"></div>
    <div class="photo-wrapper clearfix">
        <div class="photo-wrapper-tip text-center">
            <img class="about-photo" src="/images/avatar.jpg" />
        </div>
    </div>
    <div class="textwidget">
        <p class="text-center">上上下下，左右左右，BABA！</p>
    </div>
</aside>
            
                    <div class="sticky-area">
                
                    <aside id="krw-toc" class="widget widget-kratos-toc clearfix">
    <div class="photo-background"></div>
    <h4 class="widget-title no-after">
        <i class="fa fa-compass"></i>
        文章目录
        <span class="toc-progress-bar"></span>
    </h4>
    <div class="textwidget">
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8F%82%E6%95%B0%E6%9B%B4%E6%96%B0"><span class="toc-number">1.</span> <span class="toc-text">参数更新</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#SGD"><span class="toc-number">1.1.</span> <span class="toc-text">SGD</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#SGD%E7%BC%BA%E7%82%B9"><span class="toc-number">1.1.1.</span> <span class="toc-text">SGD缺点</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Momentum"><span class="toc-number">1.2.</span> <span class="toc-text">Momentum</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#AdaGrad"><span class="toc-number">1.3.</span> <span class="toc-text">AdaGrad</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Adm"><span class="toc-number">1.4.</span> <span class="toc-text">Adm</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%9D%83%E9%87%8D%E7%9A%84%E5%88%9D%E5%A7%8B%E5%80%BC"><span class="toc-number">2.</span> <span class="toc-text">权重的初始值</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9A%90%E8%97%8F%E5%B1%82%E7%9A%84%E6%BF%80%E6%B4%BB%E5%80%BC%E7%9A%84%E5%88%86%E5%B8%83"><span class="toc-number">2.1.</span> <span class="toc-text">隐藏层的激活值的分布</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ReLu%E5%88%9D%E5%A7%8B%E5%80%BC"><span class="toc-number">2.2.</span> <span class="toc-text">ReLu初始值</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Batch-Normalization"><span class="toc-number">3.</span> <span class="toc-text">Batch Normalization</span></a></li></ol>
    </div>
</aside>
                
                
  <aside id="krw-categories" class="widget widget-kratos-categories clearfix">
    <h4 class="widget-title"><i class="fa fa-folder"></i>分类目录</h4>
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Android/">Android</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/DeepLearning/">DeepLearning</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Kotlin/">Kotlin</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/OpenGL/">OpenGL</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/TensorFlow/">TensorFlow</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/hexo/">hexo</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/python/">python</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/pytorch/">pytorch</a><span class="category-list-count">7</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/pytorch/python/">python</a><span class="category-list-count">7</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%8D%9A%E6%96%87/">博文</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/">数据库</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%AE%97%E6%B3%95/">算法</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0/">网络学习</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0/">论文学习</a><span class="category-list-count">1</span></li></ul>
  </aside>


            
                
  <aside id="krw-tags" class="widget widget-kratos-tags clearfix">
    <h4 class="widget-title"><i class="fa fa-tags"></i>标签聚合</h4>
      <div class="tag-clouds">
        <a href="/tags/A/" style="font-size: 0.6em;">A*</a> <a href="/tags/Android/" style="font-size: 0.6em;">Android</a> <a href="/tags/C-C/" style="font-size: 0.6em;">C/C++</a> <a href="/tags/CycleGan/" style="font-size: 0.6em;">CycleGan</a> <a href="/tags/DeepLearning/" style="font-size: 0.8em;">DeepLearning</a> <a href="/tags/Kotlin/" style="font-size: 0.8em;">Kotlin</a> <a href="/tags/OpenGL/" style="font-size: 0.67em;">OpenGL</a> <a href="/tags/TensorFlow/" style="font-size: 0.73em;">TensorFlow</a> <a href="/tags/android/" style="font-size: 0.6em;">android</a> <a href="/tags/app/" style="font-size: 0.6em;">app</a> <a href="/tags/bfs/" style="font-size: 0.6em;">bfs</a> <a href="/tags/cgan/" style="font-size: 0.6em;">cgan</a> <a href="/tags/conditional-GAN/" style="font-size: 0.6em;">conditional GAN</a> <a href="/tags/deeplearning/" style="font-size: 0.6em;">deeplearning</a> <a href="/tags/gan/" style="font-size: 0.6em;">gan</a> <a href="/tags/hexo/" style="font-size: 0.6em;">hexo</a> <a href="/tags/html5/" style="font-size: 0.6em;">html5</a> <a href="/tags/java/" style="font-size: 0.67em;">java</a>
      </div>
  </aside>

            
                
  <aside id="krw-posts" class="widget widget-kratos-posts">
  <h4 class="widget-title"><i class="fa fa-file"></i>最新文章</h4>
  <div class="tab-content">
      <ul class="list-group">
        
        
          
          
            <a class="list-group-item" href="/2022/01/06/%E4%B8%89%E7%A7%8D%E4%B8%8A%E9%87%87%E6%A0%B7%E7%9A%84%E6%96%B9%E5%BC%8F%E6%80%BB%E7%BB%93/"><i class="fa  fa-book"></i> 三种上采样的方式总结</a>
            
          
        
          
          
            <a class="list-group-item" href="/2022/01/05/SegNet%E5%AD%A6%E4%B9%A0%E5%8F%8A%E5%AE%9E%E7%8E%B0/"><i class="fa  fa-book"></i> SegNet学习及实现</a>
            
          
        
          
          
            <a class="list-group-item" href="/2021/12/02/GoogleNet%E5%AD%A6%E4%B9%A0%E5%8F%8A%E5%AE%9E%E7%8E%B0/"><i class="fa  fa-book"></i> GoogleNet学习及实现</a>
            
          
        
          
          
            <a class="list-group-item" href="/2021/11/23/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/"><i class="fa  fa-book"></i> 模型评估</a>
            
          
        
          
          
            <a class="list-group-item" href="/2021/11/15/%E7%99%BD%E5%AB%96googleGPU%E8%B5%84%E6%BA%90%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/"><i class="fa  fa-book"></i> 白嫖googleGPU资源训练模型</a>
            
          
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
      </ul>
  </div>
  </aside>

            
    </div>
</section>
        
        </div>
    </div>
</div>
<footer>
    <div id="footer"  class="ap-lrc"  >
        <div class="kr-tool text-center">
            <div class="tool">
                
                    <div class="box search-box">
                        <a href="/search/">
                            <span class="fa fa-search"></span>
                        </a>
                    </div>
                
                
                    <div class="box theme-box" id="darkmode-switch">
                        <span class="fa fa-adjust"></span>
                    </div>
                
                
            </div>
            <div class="box gotop-box">
                <span class="fa fa-chevron-up"></span>
            </div>
        </div>
        <div class="container">
            <div class="row">
                <div class="col-md-6 col-md-offset-3 footer-list text-center">
                    <ul class="kratos-social-icons">
                        
                        
                        
                        
                        
                        
                        
                        
                        
                    </ul>
                    <ul class="kratos-copyright">
                        <div>
                            <li>&copy; 2022 菠萝菠萝卜的博客 版权所有.</li>
                            <li>本站已运行<span id="span_dt">Loading...</span></li>
                        </div>
                        <div>
                            <li>Theme <a href="https://github.com/Candinya/Kratos-Rebirth" target="_blank">Kratos:Rebirth</a></li>
                            <li>Site built with&nbsp;<i class="fa fa-heart throb" style="color:#d43f57"></i>&nbsp;by 菠萝菠萝卜.</li>
                        </div>
                        <div>
                            <li>Powered by <a href="https://hexo.io" target="_blank" rel="nofollow">Hexo</a></li>
                            <li>Hosted on <a href="https://github.io" target="_blank">Github Pages</a></li>
                        </div>
                        <div>
                            
                            
                        </div>
                    </ul>
                </div>
            </div>
        </div>
    </div>
</footer>
</div>
</div>

        <script defer src="https://cdn.jsdelivr.net/npm/bootstrap@3.3.4/dist/js/bootstrap.min.js"></script>
<script defer src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.js"></script>
<script>const notMobile = (!(navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i)));</script>

    <div>
        <canvas id="snow"></canvas>
        <script async type="text/javascript" src="/js/snow.min.js"></script>
    </div>

<script async src="/js/candy.min.js"></script>

    <script defer src="https://cdn.jsdelivr.net/npm/aplayer@1.10.1/dist/APlayer.min.js"></script>
    
    <script defer src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>
    <meting-js
        server="netease"
        type="playlist"
        id="1469580721"
        order="random"
        fixed="true"
    >
    </meting-js>



    <script defer src="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>

<script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.6/dist/clipboard.min.js"></script>
<script defer src="/js/kratosr.min.js"></script>
<script defer src="/js/pjax.min.js"></script>

    <script defer src="https://cdn.jsdelivr.net/npm/layui-src@2.5.5/dist/layui.all.js"></script>


    <script defer src="/js/kr-dark.min.js"></script>



<!-- Extra support for third-party plguins  -->


    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<!-- <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>-->
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/assets/hijiki.model.json"},"log":false});</script></body>
</html>