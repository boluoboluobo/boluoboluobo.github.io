<!DOCTYPE html>
<html lang="zh-CN">
    <head>
  <!-- 元数据 -->
  <meta charset="utf-8">
  <link rel="icon" href="">
  <title>pytorch入门笔记01 | 菠萝菠萝卜的博客</title>
  <meta name="author" content="菠萝菠萝卜" />
  <meta http-equiv="Cache-Control" content="no-transform" />
  <meta http-equiv="Cache-Control" content="no-siteapp" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="robots" content="index,follow" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  <meta name="format-detection" content="telphone=no, email=no" />
  
    <meta name="keywords" content="python, pytorch" />
  
  <meta name="description" content="Pytorch 张量标量（0D）只包含一个元素的张量为标量。类型通常为FloatTensor或LongTensor 123import torchx &#x3D; torch.rand(10)x.size()  向量（1D）12import torchx &#x3D; torch.FloatTensor([1.0,2.0,3.0,4.0])  out: torch.Size([4]) 矩阵（2D）12x &#x3D; torc">
<meta property="og:type" content="article">
<meta property="og:title" content="pytorch入门笔记01">
<meta property="og:url" content="https://boluoboluobo-github-io.vercel.app/2021/09/25/pytorch%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B001/index.html">
<meta property="og:site_name" content="菠萝菠萝卜的博客">
<meta property="og:description" content="Pytorch 张量标量（0D）只包含一个元素的张量为标量。类型通常为FloatTensor或LongTensor 123import torchx &#x3D; torch.rand(10)x.size()  向量（1D）12import torchx &#x3D; torch.FloatTensor([1.0,2.0,3.0,4.0])  out: torch.Size([4]) 矩阵（2D）12x &#x3D; torc">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://boluoboluobo-github-io.vercel.app/2021/09/25/pytorch%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B001/pytorch.jpg">
<meta property="article:published_time" content="2021-09-25T09:56:25.000Z">
<meta property="article:modified_time" content="2021-10-20T13:37:57.041Z">
<meta property="article:author" content="菠萝菠萝卜">
<meta property="article:tag" content="python">
<meta property="article:tag" content="pytorch">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://boluoboluobo-github-io.vercel.app/2021/09/25/pytorch%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B001/pytorch.jpg">
<meta name="twitter:site" content="@null">
  
  <!-- 站点验证相关 -->
  
    
    
    
  
  <!-- 样式表文件 -->
  <link rel="stylesheet" id="kratos-css" href="/css/kratosr.min.css" type="text/css" media="all">
  
    <link rel="stylesheet" id="highlight-css" href="/css/highlight/night-eighties.min.css" type="text/css" media="all">
  
  
  <link rel="stylesheet" id="fontawe-css" href="https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css" type="text/css" media="all">
  <link rel="stylesheet" id="nprogress-css" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css" type="text/css" media="all">
  
  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer@1.10.1/dist/APlayer.min.css">
  
  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css">
  
  
    <link rel="stylesheet" id="darkmode-css" href="/css/kr-dark.min.css" type="text/css" media="all">
  
  <!-- 不得不预先加载的一些JS文件 -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js"></script>
  
    <script src="https://cdn.jsdelivr.net/npm/qrcode_js@1.0.0/qrcode.min.js"></script>
  
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.0"></head>


    <body class="custom-background">
        <div id="kratos-wrapper">
    <div id="kratos-page">
        <div id="kratos-header">
            <header id="kratos-desktop-topnav" class="kratos-topnav">
                <div class="container">
                    <div class="nav-header">
                        <nav id="kratos-menu-wrap">
                            <ul id="kratos-primary-menu" class="sf-menu">
                                
                                    
                                        <li><a href="/"><i class="fa fa-home"></i>首页</a></li>
                                    
                                
                                    
                                        <li><a href="/archives/"><i class="fa fa-file"></i>档案馆</a></li>
                                    
                                
                                    
                                        <li>
                                            <a><i class="fa fa-link"></i>链接</a>
                                            <ul class="sub-menu">
                                                
                                                    
                                                
                                                    
                                                        <li><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_36571422">CSDN博客</a></li>
                                                    
                                                
                                            </ul>
                                        </li>
                                    
                                
                            </ul>
                        </nav>
                    </div>
                </div>
            </header>
            <header id="kratos-mobile-topnav" class="kratos-topnav">
                <div class="container">
                    <div class="color-logo"><a href="/">菠萝菠萝卜的博客</a></div>
                    <div class="nav-toggle">
                        <a class="kratos-nav-toggle js-kratos-nav-toggle">
                            <i></i>
                        </a>
                    </div>
                </div>
            </header>
        </div>
        <div class="kratos-start kratos-hero-2">
            <!-- <div class="kratos-overlay"></div> -->
            <div class="kratos-cover kratos-cover-2 text-center">
                <div class="desc desc2 animate-box">
                    <a href="/">
                        <h2>菠萝菠萝卜的博客</h2> <br />
                        <span></span>
                    </a>
                </div>
            </div>
        </div>

        <div id="kratos-blog-post">
            <div class="container">
                <div id="main" class="row">
                    

        <section class="col-md-8">
    <article>
        <div class="kratos-hentry kratos-post-inner clearfix">
            <header class="kratos-entry-header">
                <h1 class="kratos-entry-title text-center">pytorch入门笔记01</h1>
                
                <ul class="kratos-post-meta text-center">
                    <li><i class="fa fa-calendar"></i> 2021-09-25</li>
                    <li><i class="fa fa-user"></i> 作者 菠萝菠萝卜</li>
                    <li>
                        <i class="fa fa-edit"></i> 
                        
                        
                            ~5.81K
                        
                        字
                    </li>
                    
                        <li id="/2021/09/25/pytorch%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B001/" class="leancloud_visitors" data-flag-title="pytorch入门笔记01">
                            <i class="fa fa-eye"></i>
                            <span class="leancloud-visitors-count"> </span> 次阅读
                        </li>
                        
                    
                </ul>
            </header>
            <div class="kratos-post-content">
                <div id="expire-alert" class="alert alert-warning hidden" role="alert">
                    本文最后编辑于 <time datetime="1634737077041"></time> 前，其中的内容可能需要更新。
                </div>
                
                    <div class="kratos-post-inner-toc">
                        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Pytorch-%E5%BC%A0%E9%87%8F"><span class="toc-number">1.</span> <span class="toc-text">Pytorch 张量</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A0%87%E9%87%8F%EF%BC%880D%EF%BC%89"><span class="toc-number">1.1.</span> <span class="toc-text">标量（0D）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%91%E9%87%8F%EF%BC%881D%EF%BC%89"><span class="toc-number">1.2.</span> <span class="toc-text">向量（1D）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9F%A9%E9%98%B5%EF%BC%882D%EF%BC%89"><span class="toc-number">1.3.</span> <span class="toc-text">矩阵（2D）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E7%BB%B4%E5%90%91%E9%87%8F"><span class="toc-number">1.4.</span> <span class="toc-text">三维向量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%87%E7%89%87%E5%BC%A0%E9%87%8F"><span class="toc-number">1.5.</span> <span class="toc-text">切片张量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E7%BB%B4%E5%BC%A0%E9%87%8F"><span class="toc-number">1.6.</span> <span class="toc-text">四维张量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%E7%BB%B4%E5%BC%A0%E9%87%8F"><span class="toc-number">1.7.</span> <span class="toc-text">五维张量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#GPU%E4%B8%8A%E7%9A%84%E5%BC%A0%E9%87%8F"><span class="toc-number">1.8.</span> <span class="toc-text">GPU上的张量</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%B8%B8%E8%A7%81%E7%9A%84%E6%96%B9%E6%B3%95"><span class="toc-number">2.</span> <span class="toc-text">常见的方法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%A4%E6%96%ADGPU%E6%98%AF%E5%90%A6%E5%8F%AF%E7%94%A8"><span class="toc-number">2.1.</span> <span class="toc-text">判断GPU是否可用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%94%9F%E6%88%90%E7%A9%BA%E7%9F%A9%E9%98%B5"><span class="toc-number">2.2.</span> <span class="toc-text">生成空矩阵</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="toc-number">2.3.</span> <span class="toc-text">随机初始化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E9%9B%B6%E7%9F%A9%E9%98%B5"><span class="toc-number">2.4.</span> <span class="toc-text">创建零矩阵</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9E%84%E9%80%A0%E4%B8%80%E4%B8%AA%E5%BC%A0%E9%87%8F"><span class="toc-number">2.5.</span> <span class="toc-text">构造一个张量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%8E%B7%E5%8F%96%E7%BB%B4%E5%BA%A6%E4%BF%A1%E6%81%AF"><span class="toc-number">2.6.</span> <span class="toc-text">获取维度信息</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8A%A0%E6%B3%95"><span class="toc-number">2.7.</span> <span class="toc-text">加法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#numpy%E4%B8%80%E6%A0%B7%E6%A0%87%E5%87%86%E7%9A%84%E7%B4%A2%E5%BC%95%E5%92%8C%E5%88%87%E7%89%87"><span class="toc-number">2.8.</span> <span class="toc-text">numpy一样标准的索引和切片</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B9%98%E6%B3%95"><span class="toc-number">2.9.</span> <span class="toc-text">乘法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%9E%E6%8E%A5%E5%BC%A0%E9%87%8F"><span class="toc-number">2.10.</span> <span class="toc-text">连接张量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%94%B9%E5%8F%98tensor%E7%9A%84%E5%BD%A2%E7%8A%B6"><span class="toc-number">2.11.</span> <span class="toc-text">改变tensor的形状</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%8E%B7%E5%8F%96%E6%A0%87%E9%87%8F%E7%9A%84%E5%80%BC"><span class="toc-number">2.12.</span> <span class="toc-text">获取标量的值</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#numpy%E5%92%8Ctensor%E7%9B%B8%E4%BA%92%E8%BD%AC%E6%8D%A2"><span class="toc-number">2.13.</span> <span class="toc-text">numpy和tensor相互转换</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E5%AD%98%E5%92%8C%E8%AF%BB%E5%8F%96"><span class="toc-number">2.14.</span> <span class="toc-text">模型的保存和读取</span></a></li></ol></li></ol>
                    </div>
                
                <hr />
                <h1 id="Pytorch-张量"><a href="#Pytorch-张量" class="headerlink" title="Pytorch 张量"></a>Pytorch 张量</h1><h2 id="标量（0D）"><a href="#标量（0D）" class="headerlink" title="标量（0D）"></a>标量（0D）</h2><p>只包含一个元素的张量为<strong>标量</strong>。类型通常为FloatTensor或LongTensor</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">x = torch.rand(<span class="number">10</span>)</span><br><span class="line">x.size()</span><br></pre></td></tr></table></figure>

<h2 id="向量（1D）"><a href="#向量（1D）" class="headerlink" title="向量（1D）"></a>向量（1D）</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">x = torch.FloatTensor([<span class="number">1.0</span>,<span class="number">2.0</span>,<span class="number">3.0</span>,<span class="number">4.0</span>])</span><br></pre></td></tr></table></figure>

<p>out:</p>
<p>torch.Size([4])</p>
<h2 id="矩阵（2D）"><a href="#矩阵（2D）" class="headerlink" title="矩阵（2D）"></a>矩阵（2D）</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.FloatTensor([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]])</span><br><span class="line"><span class="built_in">print</span>(x.size())</span><br></pre></td></tr></table></figure>

<p>out:</p>
<p>torch.Size([2, 2])</p>
<h2 id="三维向量"><a href="#三维向量" class="headerlink" title="三维向量"></a>三维向量</h2><p>多个矩阵累加在一起。比如一张图片，有三个通道，每个通道都有一个矩阵。此处的pic2.jpg是一个28x28x3的图片。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line">src = cv.imread(<span class="string">&#x27;../pic2.jpg&#x27;</span>)</span><br><span class="line">matrix = np.array(src)</span><br><span class="line">tensor = torch.from_numpy(matrix)</span><br><span class="line"><span class="built_in">print</span>(tensor.size())</span><br></pre></td></tr></table></figure>

<p>out:</p>
<p>torch.Size([28, 28, 3])</p>
<h2 id="切片张量"><a href="#切片张量" class="headerlink" title="切片张量"></a>切片张量</h2><p>这里和python的用法一样</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sales = torch.FloatTensor([<span class="number">1.0</span>,<span class="number">2.0</span>,<span class="number">3.0</span>,<span class="number">4.0</span>,<span class="number">5.0</span>])</span><br><span class="line"><span class="built_in">print</span>(sales[:<span class="number">2</span>])</span><br></pre></td></tr></table></figure>

<p>out:</p>
<p>tensor([1., 2.])</p>
<p>对于前面的如果需要其中一个通道。一种用切片向量，一种用opencv的split方法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line">src = cv.imread(<span class="string">&#x27;../pic2.jpg&#x27;</span>)</span><br><span class="line">matrix = np.array(src)</span><br><span class="line">tensor = torch.from_numpy(matrix)</span><br><span class="line"><span class="comment">#切片</span></span><br><span class="line">qp_tensor = tensor[:,:,<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(qp_tensor.size)</span><br><span class="line"></span><br><span class="line"><span class="comment">#opencv方法</span></span><br><span class="line">b,g,r = cv.split(src)</span><br></pre></td></tr></table></figure>

<h2 id="四维张量"><a href="#四维张量" class="headerlink" title="四维张量"></a>四维张量</h2><p>对于多张图片，批处理那种</p>
<h2 id="五维张量"><a href="#五维张量" class="headerlink" title="五维张量"></a>五维张量</h2><p>视频数据。</p>
<h2 id="GPU上的张量"><a href="#GPU上的张量" class="headerlink" title="GPU上的张量"></a>GPU上的张量</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line">a = torch.rand(<span class="number">10000</span>,<span class="number">10000</span>)</span><br><span class="line">b = torch.rand(<span class="number">10000</span>,<span class="number">10000</span>)</span><br><span class="line"></span><br><span class="line">cpustart = time.time()</span><br><span class="line">a.matmul(b)</span><br><span class="line">cpuEnd = time.time()</span><br><span class="line"><span class="comment">#将张量转移到GPU</span></span><br><span class="line">a = a.cuda()</span><br><span class="line">b = b.cuda()</span><br><span class="line"></span><br><span class="line">gpustart = time.time()</span><br><span class="line">a.matmul(b)</span><br><span class="line">gpuEnd = time.time()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;CPU cost: &quot;</span> + <span class="built_in">str</span>(cpuEnd - cpustart))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;GPU cost: &quot;</span> + <span class="built_in">str</span>(gpuEnd - gpustart))</span><br></pre></td></tr></table></figure>

<p>out:</p>
<p>CPU cost: 7.888931035995483<br>GPU cost: 0.1765275001525879</p>
<h1 id="常见的方法"><a href="#常见的方法" class="headerlink" title="常见的方法"></a>常见的方法</h1><h2 id="判断GPU是否可用"><a href="#判断GPU是否可用" class="headerlink" title="判断GPU是否可用"></a>判断GPU是否可用</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    tensor = tensor.to(<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;device tensor is stored on: <span class="subst">&#123;tensor.device&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="生成空矩阵"><a href="#生成空矩阵" class="headerlink" title="生成空矩阵"></a>生成空矩阵</h2><p>没有初始化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="comment"># 构造一个5 x 3的矩阵,没有初始化</span></span><br><span class="line">x = torch.empty(<span class="number">5</span>,<span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br></pre></td></tr></table></figure>

<p>out:</p>
<p>tensor([[9.3673e-39, 9.5511e-39, 1.0194e-38],<br>        [4.2246e-39, 1.0286e-38, 1.0653e-38],<br>        [1.0194e-38, 8.4490e-39, 1.0469e-38],<br>        [9.3674e-39, 9.9184e-39, 8.7245e-39],<br>        [9.2755e-39, 8.9082e-39, 9.9184e-39]])</p>
<h2 id="随机初始化"><a href="#随机初始化" class="headerlink" title="随机初始化"></a>随机初始化</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构造一个随机初始化的矩阵</span></span><br><span class="line">x1 = torch.rand(<span class="number">5</span>,<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<p>out:</p>
<p>tensor([[0.4749, 0.0095, 0.4786],<br>        [0.5207, 0.4228, 0.0364],<br>        [0.8313, 0.9352, 0.6975],<br>        [0.2701, 0.5206, 0.8709],<br>        [0.3670, 0.3378, 0.9704]])</p>
<h2 id="创建零矩阵"><a href="#创建零矩阵" class="headerlink" title="创建零矩阵"></a>创建零矩阵</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构造一个矩阵全为0，数据类型是long类型的</span></span><br><span class="line">x2 = torch.zeros(<span class="number">5</span>,<span class="number">3</span>,dtype=torch.long)</span><br></pre></td></tr></table></figure>

<p>out:</p>
<p>tensor([[0, 0, 0],<br>        [0, 0, 0],<br>        [0, 0, 0],<br>        [0, 0, 0],<br>        [0, 0, 0]])</p>
<h2 id="构造一个张量"><a href="#构造一个张量" class="headerlink" title="构造一个张量"></a>构造一个张量</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#构造一个张量，直接使用数据</span></span><br><span class="line">x3 = torch.tensor([<span class="number">5.5</span>,<span class="number">3</span>])</span><br></pre></td></tr></table></figure>

<p>out:</p>
<p>tensor([5.5000, 3.0000])</p>
<p><strong>基于一个已存在的tensor创建一个</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个tensor基于已经存在的tensor</span></span><br><span class="line">x4 = x.new_ones(<span class="number">5</span>,<span class="number">3</span>,dtype=torch.double)</span><br><span class="line"><span class="comment">#Tensor.new_ones 返回一个与size大小相同的用1填充的张量，</span></span><br><span class="line"><span class="comment">#默认情况下，返回的Tensor具有次张量相同的torch.dtype和torch.device</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># randn_like,基于已存在的tensor，创建随机相似的</span></span><br><span class="line">x5 = torch.randn_like(x4,dtype=torch.<span class="built_in">float</span>)</span><br><span class="line"><span class="built_in">print</span>(x4)</span><br><span class="line"><span class="built_in">print</span>(x5)</span><br></pre></td></tr></table></figure>

<p>out:</p>
<p>tensor([[1., 1., 1.],<br>        [1., 1., 1.],<br>        [1., 1., 1.],<br>        [1., 1., 1.],<br>        [1., 1., 1.]], dtype=torch.float64)<br>tensor([[-0.7830,  0.2870,  0.3721],<br>        [ 0.2931,  0.4255,  0.3800],<br>        [-0.1016,  0.6011, -0.7567],<br>        [ 0.4526, -1.0510, -0.4116],<br>        [ 1.4605,  1.4378,  0.4322]])</p>
<h2 id="获取维度信息"><a href="#获取维度信息" class="headerlink" title="获取维度信息"></a>获取维度信息</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#获取维度信息</span></span><br><span class="line"><span class="built_in">print</span>(x5.size())</span><br></pre></td></tr></table></figure>
<p>out:</p>
<p>torch.Size([5, 3])</p>
<h2 id="加法"><a href="#加法" class="headerlink" title="加法"></a>加法</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#######################加法####################</span></span><br><span class="line">y1 = torch.ones(<span class="number">5</span>,<span class="number">3</span>) <span class="comment">#创建一个全是1的矩阵</span></span><br><span class="line"><span class="built_in">print</span>(x4 + y1)</span><br><span class="line">x6 = torch.add(x4,y1)</span><br><span class="line">torch.add(x4,y1,out=x) <span class="comment">#提供输出tensor作为参数</span></span><br><span class="line"><span class="comment">#还可以in-place</span></span><br><span class="line">y1.add_(x4)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 任何使张量发生变化的操作都有一个前缀&#x27;_&#x27;</span></span><br></pre></td></tr></table></figure>

<p>out:</p>
<p>tensor([[2., 2., 2.],<br>        [2., 2., 2.],<br>        [2., 2., 2.],<br>        [2., 2., 2.],<br>        [2., 2., 2.]])</p>
<h2 id="numpy一样标准的索引和切片"><a href="#numpy一样标准的索引和切片" class="headerlink" title="numpy一样标准的索引和切片"></a>numpy一样标准的索引和切片</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">tensor = torch.ones(<span class="number">4</span>,<span class="number">4</span>)</span><br><span class="line">tensor[:,<span class="number">1</span>] = <span class="number">0</span></span><br><span class="line"><span class="built_in">print</span>(tensor)</span><br></pre></td></tr></table></figure>

<p>out:</p>
<p>tensor([[1., 0., 1., 1.],<br>        [1., 0., 1., 1.],<br>        [1., 0., 1., 1.],<br>        [1., 0., 1., 1.]])</p>
<h2 id="乘法"><a href="#乘法" class="headerlink" title="乘法"></a>乘法</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">a = torch.rand(<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">b = torch.rand(<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line"><span class="comment">#乘法 对应位置相乘</span></span><br><span class="line"><span class="built_in">print</span>(a * b)</span><br><span class="line"><span class="built_in">print</span>(a.mul(b))</span><br><span class="line"><span class="comment">#自身乘法，相当于a = a * b</span></span><br><span class="line"><span class="built_in">print</span>(a.mul_(b))</span><br><span class="line"><span class="built_in">print</span>(a)</span><br></pre></td></tr></table></figure>

<p>矩阵乘法计算，行乘列求和的那种</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mul = tensor.matmul(tensor.t())</span><br><span class="line">mul2 = tensor @ tensor.t()</span><br><span class="line"><span class="built_in">print</span>(mul)</span><br><span class="line"><span class="built_in">print</span>(mul2)</span><br></pre></td></tr></table></figure>

<p>out:</p>
<p>tensor([[3., 3., 3., 3.],<br>        [3., 3., 3., 3.],<br>        [3., 3., 3., 3.],<br>        [3., 3., 3., 3.]])<br>tensor([[3., 3., 3., 3.],<br>        [3., 3., 3., 3.],<br>        [3., 3., 3., 3.],<br>        [3., 3., 3., 3.]])</p>
<h2 id="连接张量"><a href="#连接张量" class="headerlink" title="连接张量"></a>连接张量</h2><p>连接张量可以使用torch.cat。 将给定维数的张量顺序连接起来，也可以用torch.stack，另一种张量连接，略有不同</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t1 = torch.cat([tensor,tensor],dim=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(t1)</span><br></pre></td></tr></table></figure>

<p>out:</p>
<p>tensor(</p>
<p>​      [[1., 0., 1., 1., 1., 0., 1., 1.],<br>​        [1., 0., 1., 1., 1., 0., 1., 1.],<br>​        [1., 0., 1., 1., 1., 0., 1., 1.],<br>​        [1., 0., 1., 1., 1., 0., 1., 1.]])</p>
<h2 id="改变tensor的形状"><a href="#改变tensor的形状" class="headerlink" title="改变tensor的形状"></a>改变tensor的形状</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#改变tensor大小或形状 torch.view</span></span><br><span class="line">x7 = torch.randn(<span class="number">4</span>,<span class="number">4</span>)</span><br><span class="line">y = x7.view(<span class="number">16</span>)</span><br><span class="line">z = x7.view(-<span class="number">1</span>,<span class="number">8</span>) <span class="comment">#尺寸设为-1，表示自己算这个大小</span></span><br><span class="line"><span class="built_in">print</span>(x7.size(),y.size(),z.size())</span><br></pre></td></tr></table></figure>

<p>out:</p>
<p>torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])</p>
<h2 id="获取标量的值"><a href="#获取标量的值" class="headerlink" title="获取标量的值"></a>获取标量的值</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#如果只有一个tensor，使用item()可以获得这个value</span></span><br><span class="line">x8 = torch.tensor([<span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span>(x8)</span><br><span class="line"><span class="built_in">print</span>(x8.item())</span><br></pre></td></tr></table></figure>

<p>out:</p>
<p>tensor([1])<br>1</p>
<h2 id="numpy和tensor相互转换"><a href="#numpy和tensor相互转换" class="headerlink" title="numpy和tensor相互转换"></a>numpy和tensor相互转换</h2><p><strong>numpy转pytorch</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line">src = cv.imread(<span class="string">&#x27;../pic2.jpg&#x27;</span>)</span><br><span class="line">cv.imshow(<span class="string">&quot;hello&quot;</span>,src)</span><br><span class="line">matrix = np.array(src)</span><br><span class="line">panda_tensor = torch.from_numpy(matrix)</span><br><span class="line"><span class="built_in">print</span>(panda_tensor.size())</span><br><span class="line"></span><br><span class="line">cv.waitKey(<span class="number">0</span>)</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></table></figure>

<p>主要是torch.from_numpy()</p>
<p><strong>pytorch转numpy</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor = torch_data.numpy()</span><br><span class="line"><span class="comment"># torch_data是一个tensor</span></span><br></pre></td></tr></table></figure>

<h2 id="模型的保存和读取"><a href="#模型的保存和读取" class="headerlink" title="模型的保存和读取"></a>模型的保存和读取</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保存</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save</span>():</span></span><br><span class="line">    net1 = torch.nn.Sequential(</span><br><span class="line">        torch.nn.Linear(<span class="number">1</span>,<span class="number">10</span>),</span><br><span class="line">        torch.nn.ReLU(),</span><br><span class="line">        torch.nn.Linear(<span class="number">10</span>,<span class="number">1</span>)</span><br><span class="line">    )</span><br><span class="line">    optimizer = torch.optim.SGD(net1.parameters(),lr=<span class="number">0.5</span>)</span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">        prediction = net1(x)</span><br><span class="line">        loss = F.mse_loss(prediction,y)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">    torch.save(net1,<span class="string">&#x27;net.pkl&#x27;</span>) <span class="comment"># 方式1： 直接保存当前网络</span></span><br><span class="line">    torch.save(net1.state_dict(),<span class="string">&#x27;net_params.pkl&#x27;</span>) <span class="comment"># 方式2： 保存网络中的参数parameters</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">restore_net</span>():</span></span><br><span class="line">    net2 = torch.load(<span class="string">&#x27;net.pkl&#x27;</span>) <span class="comment"># 加载网络</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">restore_params</span>():</span></span><br><span class="line">    net3 = torch.nn.Sequential(</span><br><span class="line">        torch.nn.Linear(<span class="number">1</span>,<span class="number">10</span>),</span><br><span class="line">        torch.nn.ReLU(),</span><br><span class="line">        torch.nn.Linear(<span class="number">10</span>,<span class="number">1</span>)</span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># 通过Parameters加载，由于存储的是参数而不是网络，所以这个需要构建一个和保存时候一样的网络，然后加载参数即可。</span></span><br><span class="line">    <span class="comment"># 加载参数比直接加载网络要快。</span></span><br><span class="line">    net3.load_state_dict(torch.load(<span class="string">&#x27;net_params.pkl&#x27;</span>))</span><br></pre></td></tr></table></figure>


            </div>
            
                <div class="kratos-copyright text-center clearfix">
                    <h5>本作品采用 <a rel="license nofollow" target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/">知识共享署名-相同方式共享 4.0 国际许可协议</a> 进行许可</h5>
                </div>
            
            <footer class="kratos-entry-footer clearfix">
                
                    <div class="post-like-donate text-center clearfix" id="post-like-donate">
                    
                        <a class="donate" href="javascript:;"><i class="fa fa-bitcoin"></i> 打赏</a>
                    
                    
                        <a class="share" href="javascript:;"><i class="fa fa-share-alt"></i> 分享</a>
                        <div class="share-wrap" style="display: none;">
    <div class="share-group">
        <a href="javascript:;" class="share-plain qq" onclick="share('qq');" rel="nofollow">
            <div class="icon-wrap">
                <i class="fa fa-qq"></i>
            </div>
        </a>
        <a href="javascript:;" class="share-plain qzone" onclick="share('qzone');" rel="nofollow">
            <div class="icon-wrap">
                <i class="fa fa-star"></i>
            </div>
        </a>
        <a href="javascript:;" class="share-plain weixin pop style-plain" rel="nofollow">
            <div class="icon-wrap">
                <i class="fa fa-weixin"></i>
            </div>
            <div class="share-int">
                <div class="qrcode" id="wechat-qr"></div>
                <p>打开微信“扫一扫”，打开网页后点击屏幕右上角分享按钮</p>
            </div>
        </a>
        <a href="javascript:;" class="share-plain weibo" onclick="share('weibo');" rel="nofollow">
            <div class="icon-wrap">
                <i class="fa fa-weibo"></i>
            </div>
        </a>
        <a href="javascript:;" class="share-plain facebook style-plain" onclick="share('facebook');" rel="nofollow">
            <div class="icon-wrap">
                <i class="fa fa-facebook"></i>
            </div>
        </a>
        <a href="javascript:;" class="share-plain twitter style-plain" onclick="share('twitter');" rel="nofollow">
            <div class="icon-wrap">
                <i class="fa fa-twitter"></i>
            </div>
        </a>
    </div>
    <script type="text/javascript">
        $(()=>{
            new QRCode("wechat-qr", {
                text: "https://boluoboluobo-github-io.vercel.app/2021/09/25/pytorch%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B001/",
                width: 150,
                height: 150,
                correctLevel : QRCode.CorrectLevel.H
            });
        });
        function share(dest) {
            const qqBase        = "https://connect.qq.com/widget/shareqq/index.html?";
            const weiboBase     = "https://service.weibo.com/share/share.php?";
            const qzoneBase     = "https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?";
            const facebookBase  = "https://www.facebook.com/sharer/sharer.php?";
            const twitterBase   = "https://twitter.com/intent/tweet?";
            const hostUrl       = "https://boluoboluobo-github-io.vercel.app/2021/09/25/pytorch%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B001/";
            const title         = "「pytorch入门笔记01」";
            const excerpt       = `Pytorch 张量标量（0D）只包含一个元素的张量为标量。类型通常为FloatTensor或LongTensor
123import torchx = torch.rand(10)x.size()

向量（1D）12import t...`;
            let _URL;
            switch (dest) {
                case "qq"       : _URL = qqBase+"url="+hostUrl+"&title="+title+"&desc=&summary="+excerpt+"&site=cxpy";     break;
                case "weibo"    : _URL = weiboBase+"url="+hostUrl+"&title="+title+excerpt;                                 break;
                case "qzone"    : _URL = qzoneBase+"url="+hostUrl+"&title="+title+"&desc=&summary="+excerpt+"&site=cxpy";  break;
                case "facebook" : _URL = facebookBase+"u="+hostUrl;                                                        break;
                case "twitter"  : _URL = twitterBase+"text="+title+excerpt+"&url="+hostUrl;                                break;
            }
            window.open(_URL);
        };
    </script>
</div>
                    
                    </div>
                
                <div class="footer-tag clearfix">
                    <div class="pull-left">
                    <i class="fa fa-tags"></i>
                        <a class="tag-none-link" href="/tags/python/" rel="tag">python</a>, <a class="tag-none-link" href="/tags/pytorch/" rel="tag">pytorch</a>
                    </div>
                    <div class="pull-date">
                    <span>最后编辑：2021-10-20</span>
                    </div>
                </div>
            </footer>
        </div>
        
            <nav class="navigation post-navigation clearfix" role="navigation">
                
                <div class="nav-previous clearfix">
                    <a title=" hexo数学公式显示问题" href="/2021/09/24/hexo数学公式显示问题/">&lt; 上一篇</a>
                </div>
                
                
                <div class="nav-next clearfix">
                    <a title=" 深度学习入门笔记04" href="/2021/09/28/深度学习入门笔记04/">下一篇 &gt;</a>
                </div>
                
            </nav>
        
        
            <div id="v-comments" class="post-comments"></div>
<script>
    var load_comm = () => {
        const init = () => {
            new Valine({
                el: '#v-comments',
                appId: 'pnDNVddr900afG7XglGQgJCb-gzGzoHsz',
                appKey: 'HA3J9tdvziBrLcSml8Kai0qH',
                visitor: true,
                enableQQ: false,
                path: '/2021/09/25/pytorch%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B001/',
				avatar: ''
            });
        }
        if (typeof Valine == 'undefined') {
            const src = 'https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js';
            $.getScript(src, init);
        } else {
            init();
        }
    };
</script>
<noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="https://valine.js.org/">comments powered by Valine.</a></noscript>

        
    </article>
</section>

                
            

<section id="kratos-widget-area" class="col-md-4 hidden-xs hidden-sm">
    <!-- 文章和页面根据splitter来分割，没有的话就从头开始设置为sticky -->
    
    
                <aside id="krw-about" class="widget widget-kratos-about clearfix">
    <div class="photo-background"></div>
    <div class="photo-wrapper clearfix">
        <div class="photo-wrapper-tip text-center">
            <img class="about-photo" src="/images/avatar.jpg" />
        </div>
    </div>
    <div class="textwidget">
        <p class="text-center">上上下下，左右左右，BABA！</p>
    </div>
</aside>
            
                    <div class="sticky-area">
                
                    <aside id="krw-toc" class="widget widget-kratos-toc clearfix">
    <div class="photo-background"></div>
    <h4 class="widget-title no-after">
        <i class="fa fa-compass"></i>
        文章目录
        <span class="toc-progress-bar"></span>
    </h4>
    <div class="textwidget">
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Pytorch-%E5%BC%A0%E9%87%8F"><span class="toc-number">1.</span> <span class="toc-text">Pytorch 张量</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A0%87%E9%87%8F%EF%BC%880D%EF%BC%89"><span class="toc-number">1.1.</span> <span class="toc-text">标量（0D）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%91%E9%87%8F%EF%BC%881D%EF%BC%89"><span class="toc-number">1.2.</span> <span class="toc-text">向量（1D）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9F%A9%E9%98%B5%EF%BC%882D%EF%BC%89"><span class="toc-number">1.3.</span> <span class="toc-text">矩阵（2D）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E7%BB%B4%E5%90%91%E9%87%8F"><span class="toc-number">1.4.</span> <span class="toc-text">三维向量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%87%E7%89%87%E5%BC%A0%E9%87%8F"><span class="toc-number">1.5.</span> <span class="toc-text">切片张量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E7%BB%B4%E5%BC%A0%E9%87%8F"><span class="toc-number">1.6.</span> <span class="toc-text">四维张量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%E7%BB%B4%E5%BC%A0%E9%87%8F"><span class="toc-number">1.7.</span> <span class="toc-text">五维张量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#GPU%E4%B8%8A%E7%9A%84%E5%BC%A0%E9%87%8F"><span class="toc-number">1.8.</span> <span class="toc-text">GPU上的张量</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%B8%B8%E8%A7%81%E7%9A%84%E6%96%B9%E6%B3%95"><span class="toc-number">2.</span> <span class="toc-text">常见的方法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%A4%E6%96%ADGPU%E6%98%AF%E5%90%A6%E5%8F%AF%E7%94%A8"><span class="toc-number">2.1.</span> <span class="toc-text">判断GPU是否可用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%94%9F%E6%88%90%E7%A9%BA%E7%9F%A9%E9%98%B5"><span class="toc-number">2.2.</span> <span class="toc-text">生成空矩阵</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="toc-number">2.3.</span> <span class="toc-text">随机初始化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E9%9B%B6%E7%9F%A9%E9%98%B5"><span class="toc-number">2.4.</span> <span class="toc-text">创建零矩阵</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9E%84%E9%80%A0%E4%B8%80%E4%B8%AA%E5%BC%A0%E9%87%8F"><span class="toc-number">2.5.</span> <span class="toc-text">构造一个张量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%8E%B7%E5%8F%96%E7%BB%B4%E5%BA%A6%E4%BF%A1%E6%81%AF"><span class="toc-number">2.6.</span> <span class="toc-text">获取维度信息</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8A%A0%E6%B3%95"><span class="toc-number">2.7.</span> <span class="toc-text">加法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#numpy%E4%B8%80%E6%A0%B7%E6%A0%87%E5%87%86%E7%9A%84%E7%B4%A2%E5%BC%95%E5%92%8C%E5%88%87%E7%89%87"><span class="toc-number">2.8.</span> <span class="toc-text">numpy一样标准的索引和切片</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B9%98%E6%B3%95"><span class="toc-number">2.9.</span> <span class="toc-text">乘法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%9E%E6%8E%A5%E5%BC%A0%E9%87%8F"><span class="toc-number">2.10.</span> <span class="toc-text">连接张量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%94%B9%E5%8F%98tensor%E7%9A%84%E5%BD%A2%E7%8A%B6"><span class="toc-number">2.11.</span> <span class="toc-text">改变tensor的形状</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%8E%B7%E5%8F%96%E6%A0%87%E9%87%8F%E7%9A%84%E5%80%BC"><span class="toc-number">2.12.</span> <span class="toc-text">获取标量的值</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#numpy%E5%92%8Ctensor%E7%9B%B8%E4%BA%92%E8%BD%AC%E6%8D%A2"><span class="toc-number">2.13.</span> <span class="toc-text">numpy和tensor相互转换</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E5%AD%98%E5%92%8C%E8%AF%BB%E5%8F%96"><span class="toc-number">2.14.</span> <span class="toc-text">模型的保存和读取</span></a></li></ol></li></ol>
    </div>
</aside>
                
                
  <aside id="krw-categories" class="widget widget-kratos-categories clearfix">
    <h4 class="widget-title"><i class="fa fa-folder"></i>分类目录</h4>
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Android/">Android</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/DeepLearning/">DeepLearning</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Kotlin/">Kotlin</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/OpenGL/">OpenGL</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/TensorFlow/">TensorFlow</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/hexo/">hexo</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/python/">python</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/pytorch/">pytorch</a><span class="category-list-count">6</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/pytorch/python/">python</a><span class="category-list-count">6</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/">数据库</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%AE%97%E6%B3%95/">算法</a><span class="category-list-count">7</span></li></ul>
  </aside>


            
                
  <aside id="krw-tags" class="widget widget-kratos-tags clearfix">
    <h4 class="widget-title"><i class="fa fa-tags"></i>标签聚合</h4>
      <div class="tag-clouds">
        <a href="/tags/A/" style="font-size: 0.6em;">A*</a> <a href="/tags/Android/" style="font-size: 0.6em;">Android</a> <a href="/tags/C-C/" style="font-size: 0.6em;">C/C++</a> <a href="/tags/DeepLearning/" style="font-size: 0.8em;">DeepLearning</a> <a href="/tags/Kotlin/" style="font-size: 0.8em;">Kotlin</a> <a href="/tags/OpenGL/" style="font-size: 0.67em;">OpenGL</a> <a href="/tags/TensorFlow/" style="font-size: 0.73em;">TensorFlow</a> <a href="/tags/android/" style="font-size: 0.6em;">android</a> <a href="/tags/app/" style="font-size: 0.6em;">app</a> <a href="/tags/bfs/" style="font-size: 0.6em;">bfs</a> <a href="/tags/hexo/" style="font-size: 0.6em;">hexo</a> <a href="/tags/html5/" style="font-size: 0.6em;">html5</a> <a href="/tags/java/" style="font-size: 0.67em;">java</a> <a href="/tags/kaggle/" style="font-size: 0.6em;">kaggle</a> <a href="/tags/kmp/" style="font-size: 0.6em;">kmp</a> <a href="/tags/kotlin/" style="font-size: 0.6em;">kotlin</a> <a href="/tags/leetcode-%E4%B8%AD%E7%AD%89/" style="font-size: 0.73em;">leetcode(中等)</a> <a href="/tags/leetcode-%E7%AE%80%E5%8D%95/" style="font-size: 0.6em;">leetcode(简单)</a>
      </div>
  </aside>

            
                
  <aside id="krw-posts" class="widget widget-kratos-posts">
  <h4 class="widget-title"><i class="fa fa-file"></i>最新文章</h4>
  <div class="tab-content">
      <ul class="list-group">
        
        
          
          
            <a class="list-group-item" href="/2021/10/20/%E5%8A%9B%E6%89%A3%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%9820211020/"><i class="fa  fa-book"></i> 力扣每日一题 2021/10/20</a>
            
          
        
          
          
            <a class="list-group-item" href="/2021/10/19/%E5%8A%9B%E6%89%A3%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%9820211019/"><i class="fa  fa-book"></i> 力扣每日一题 2021/10/19</a>
            
          
        
          
          
            <a class="list-group-item" href="/2021/10/18/%E5%8A%9B%E6%89%A3%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%9820211018/"><i class="fa  fa-book"></i> 力扣每日一题 2021/10/18</a>
            
          
        
          
          
            <a class="list-group-item" href="/2021/10/17/%E5%8A%9B%E6%89%A3%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%9820211017/"><i class="fa  fa-book"></i> 力扣每日一题 2021/10/17</a>
            
          
        
          
          
            <a class="list-group-item" href="/2021/10/14/pytorch%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B006/"><i class="fa  fa-book"></i> pytorch入门笔记06</a>
            
          
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
      </ul>
  </div>
  </aside>

            
    </div>
</section>
        
        </div>
    </div>
</div>
<footer>
    <div id="footer"  class="ap-lrc"  >
        <div class="kr-tool text-center">
            <div class="tool">
                
                    <div class="box search-box">
                        <a href="/search/">
                            <span class="fa fa-search"></span>
                        </a>
                    </div>
                
                
                    <div class="box theme-box" id="darkmode-switch">
                        <span class="fa fa-adjust"></span>
                    </div>
                
                
            </div>
            <div class="box gotop-box">
                <span class="fa fa-chevron-up"></span>
            </div>
        </div>
        <div class="container">
            <div class="row">
                <div class="col-md-6 col-md-offset-3 footer-list text-center">
                    <ul class="kratos-social-icons">
                        
                        
                        
                        
                        
                        
                        
                        
                        
                    </ul>
                    <ul class="kratos-copyright">
                        <div>
                            <li>&copy; 2021 菠萝菠萝卜的博客 版权所有.</li>
                            <li>本站已运行<span id="span_dt">Loading...</span></li>
                        </div>
                        <div>
                            <li>Theme <a href="https://github.com/Candinya/Kratos-Rebirth" target="_blank">Kratos:Rebirth</a></li>
                            <li>Site built with&nbsp;<i class="fa fa-heart throb" style="color:#d43f57"></i>&nbsp;by 菠萝菠萝卜.</li>
                        </div>
                        <div>
                            <li>Powered by <a href="https://hexo.io" target="_blank" rel="nofollow">Hexo</a></li>
                            <li>Hosted on <a href="https://github.io" target="_blank">Github Pages</a></li>
                        </div>
                        <div>
                            
                            
                        </div>
                    </ul>
                </div>
            </div>
        </div>
    </div>
</footer>
</div>
</div>

        <script defer src="https://cdn.jsdelivr.net/npm/bootstrap@3.3.4/dist/js/bootstrap.min.js"></script>
<script defer src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.js"></script>
<script>const notMobile = (!(navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i)));</script>

    <div>
        <canvas id="snow"></canvas>
        <script async type="text/javascript" src="/js/snow.min.js"></script>
    </div>

<script async src="/js/candy.min.js"></script>

    <script defer src="https://cdn.jsdelivr.net/npm/aplayer@1.10.1/dist/APlayer.min.js"></script>
    
    <script defer src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>
    <meting-js
        server="netease"
        type="playlist"
        id="1469580721"
        order="random"
        fixed="true"
    >
    </meting-js>



    <script defer src="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>

<script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.6/dist/clipboard.min.js"></script>
<script defer src="/js/kratosr.min.js"></script>
<script defer src="/js/pjax.min.js"></script>

    <script defer src="https://cdn.jsdelivr.net/npm/layui-src@2.5.5/dist/layui.all.js"></script>


    <script defer src="/js/kr-dark.min.js"></script>



<!-- Extra support for third-party plguins  -->


    <script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/assets/hijiki.model.json"},"log":false});</script></body>
</html>